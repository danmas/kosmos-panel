# AI Промпты в Kosmos Panel

Как устроены и где используются системные промпты для ИИ.

---

## 1. Терминальные команды (AI_SYSTEM_PROMPT)

**Ключ:** `AI_SYSTEM_PROMPT` в `prompts.json` (fallback: `process.env` / config.json, иначе встроенный дефолт в `server/prompts.js`).

**Где срабатывает:** Пользователь вводит в WebSocket-терминале строку с префиксом `ai:` (например `ai: покажи файлы`). Обработка — `server/ws.js` (блок AI-запроса по WebSocket).

**Как используется:**
- Системный промпт для чата: `getPrompt('AI_SYSTEM_PROMPT')`.
- Опционально в начало системного промпта добавляется контекст с **удалённой машины**: содержимое `./.kosmos-panel/ai_system_promt.md` или `~/.config/kosmos-panel/ai_system_promt.md` (читается по SSH с той же сессии).
- В `user` передаётся текст запроса пользователя (без префикса `ai:`).
- Ожидается **одна** shell-команда в ответ. Она выполняется на удалённом сервере по SSH, вывод возвращается в терминал.

**Итог:** один запрос к AI → одна команда → один запуск на сервере.

---

## 2. Multi-step Skills (SKILL_SYSTEM_PROMPT_WITH_ASK)

**Ключ:** `SKILL_SYSTEM_PROMPT_WITH_ASK` в `prompts.json` (fallback: встроенный дефолт в `server/prompts.js`).

**Где срабатывает:** Запуск скилла из терминала (например команда-скилл) или через API скиллов. Сборка промпта — `server/skill-ai.js` → `buildSkillSystemPrompt()`.

**Как используется:**
- Базовый системный промпт: `getPrompt('SKILL_SYSTEM_PROMPT_WITH_ASK')`.
- К нему добавляются: опционально контекст с удалённой машины (как в п.1), затем блок **Active Skill** — содержимое SKILL.md выбранного скилла.
- Модель должна отвечать **строго** в одном из форматов: `[CMD]`, `[ASK]`, `[ASK:optional]`, `[MESSAGE]`, `[DONE]`. Ответ разбирается в `parseSkillResponse()`.
- Цикл: запрос к AI → разбор ответа → выполнение команды / показ вопроса пользователю / информационного сообщения / завершение. До появления `[DONE]` история дополняется и отправляется следующий запрос.

**Итог:** скилл — пошаговый сценарий с командами, обязательными и опциональными вопросами к пользователю и информационными сообщениями.

---

## 3. Справка по системе (AI_SYSTEM_PROMPT_HELP)

**Ключ:** `AI_SYSTEM_PROMPT_HELP` в config.json (или `process.env`). Не в prompts.json.

**Где срабатывает:** POST `/api/ai-help` в `server.js`. Вызывается из веб-интерфейса (вопрос пользователя по документации).

**Как используется:**
- Системный промпт: `process.env.AI_SYSTEM_PROMPT_HELP` (есть встроенный дефолт в коде).
- К нему дописывается блок «Документация системы»: содержимое файлов из `AI_HELP_CONTEXT_FILES` (config) или по умолчанию файлы из папки `KB/`.
- В `user` — текст вопроса. Ответ модели возвращается клиенту как текст справки (обычно на русском).

**Итог:** один запрос — один ответ по документации системы, без выполнения команд.

---

## 4. Общее

- **Префикс команд в терминале:** по умолчанию `ai:`; настраивается через `AI_COMMAND_PREFIX` (config/env). Только такие строки обрабатываются как запрос к AI (п.1).
- **Контекстные файлы на удалённой машине** (`.kosmos-panel/ai_system_promt.md`, `~/.config/kosmos-panel/ai_system_promt.md`) используются только для **терминального AI** (п.1) и опционально для **скиллов** (п.2).
- **Загрузка промптов:** `server/prompts.js` → `getPrompt(key)`. Источник для `AI_SYSTEM_PROMPT` и `SKILL_SYSTEM_PROMPT_WITH_ASK` — `prompts.json` в корне проекта; пример — `prompts.json.example`. Промпт справки (п.3) берётся только из config/env.
